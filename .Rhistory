# 1. For Player 1's RWB
add.constraint(lp_player2, c(0, 0, 0, -400, 200, -100, 1), ">=", 0)
# 2. For Player 1's RBW
add.constraint(lp_player2, c(0, 0, -400, 0, 0, -400, 1), ">=", 0)
# 3. For Player 1's WRB
add.constraint(lp_player2, c(0, 200, 0, 0, 0, -400, 1), ">=", 0)
# 4. For Player 1's WBR
add.constraint(lp_player2, c(400, 0, 0, 0, -400, 0, 1), ">=", 0)
# 5. For Player 1's BRW
add.constraint(lp_player2, c(-400, 0, 0, 400, 0, 0, 1), ">=", 0)
# 6. For Player 1's BWR
add.constraint(lp_player2, c(0, -400, 250, 0, 0, 0, 1), ">=", 0)
# Probabilities must sum to 1
add.constraint(lp_player2, c(1, 1, 1, 1, 1, 1, 0), "=", 1)
# Set non-negativity constraints for the probabilities
set.bounds(lp_player2, lower = c(0, 0, 0, 0, 0, 0, -Inf), columns = 1:7)
# Solve the LP
solve_status <- solve(lp_player2)
# Check if the solution was found successfully (0 = success)
if (solve_status == 0) {
# Get the value of the game
v_value <- get.objective(lp_player2)
cat("Player 1's expected value (max payoff):", v_value, "\n")
# Get Player 1's optimal strategy (probabilities)
optimal_strategy_player1 <- get.variables(lp_player2)
cat("Player 1's optimal strategy (RWB, RBW, WRB, WBR, BRW, BWR probabilities):", optimal_strategy_player1[1:6], "\n")
} else {
cat("The model could not be solved. Status code:", solve_status, "\n")
}
# Load the lpSolveAPI package
library(lpSolveAPI)
# Create an LP model with 7 variables: 6 probabilities for Player 1 and v (the value of the game)
lp_player2 <- make.lp(0, 7)
lp.control(lp_player2,sense="minimize")
# Objective: Maximize v (the last variable, representing the value of the game)
set.objfn(lp_player2, c(0, 0, 0, 0, 0, 0, 1))
# 1. For Player 1's RWB
add.constraint(lp_player2, c(0, 0, 0, -400, 200, -100, 1), ">=", 0)
# 2. For Player 1's RBW
add.constraint(lp_player2, c(0, 0, -400, 0, 0, -400, 1), ">=", 0)
# 3. For Player 1's WRB
add.constraint(lp_player2, c(0, 200, 0, 0, 0, -400, 1), ">=", 0)
# 4. For Player 1's WBR
add.constraint(lp_player2, c(400, 0, 0, 0, -400, 0, 1), ">=", 0)
# 5. For Player 1's BRW
add.constraint(lp_player2, c(-400, 0, 0, 400, 0, 0, 1), ">=", 0)
# 6. For Player 1's BWR
add.constraint(lp_player2, c(0, -400, 250, 0, 0, 0, 1), ">=", 0)
# Probabilities must sum to 1
add.constraint(lp_player2, c(1, 1, 1, 1, 1, 1, 0), "=", 1)
# Set non-negativity constraints for the probabilities
set.bounds(lp_player2, lower = c(0, 0, 0, 0, 0, 0, -Inf), columns = 1:7)
# Solve the LP
solve_status <- solve(lp_player2)
# Check if the solution was found successfully (0 = success)
if (solve_status == 0) {
# Get the value of the game
v_value <- get.objective(lp_player2)
cat("Player 2's expected value (max payoff):", v_value, "\n")
# Get Player 2's optimal strategy (probabilities)
optimal_strategy_player1 <- get.variables(lp_player2)
cat("Player 2's optimal strategy (RWB, RBW, WRB, WBR, BRW, BWR probabilities):", optimal_strategy_player1[1:6], "\n")
} else {
cat("The model could not be solved. Status code:", solve_status, "\n")
}
# Check if the solution was found successfully (0 = success)
if (solve_status == 0) {
# Get the value of the game
v_value <- get.objective(lp_player1)
cat("Player 1's expected value (max payoff):", v_value, "\n")
# Get Player 1's optimal strategy (probabilities)
optimal_strategy_player1 <- get.variables(lp_player1)
cat("Player 1's optimal strategy (RWB, RBW, WRB, WBR, BRW, BWR probabilities):", optimal_strategy_player1[1:6], "\n")
} else {
cat("The model could not be solved. Status code:", solve_status, "\n")
}
# Load the lpSolveAPI package
library(lpSolveAPI)
# Create an LP model with 7 variables: 6 probabilities for Player 1 and v (the value of the game)
lp_player1 <- make.lp(0, 7)
lp.control(lp_player1,sense="maximize")
# Objective: Maximize v (the last variable, representing the value of the game)
set.objfn(lp_player1, c(0, 0, 0, 0, 0, 0, 1))
# Constraints based on Player 2's strategies
# 1. For Player 2's RWB
add.constraint(lp_player1, c(0, 0, 0, 400, -400, 0, 1), "<=", 0)
# 2. For Player 2's RBW
add.constraint(lp_player1, c(0, 0, 200, 0, 0, -400, 1), "<=", 0)
# 3. For Player 2's WRB
add.constraint(lp_player1, c(0, -400, 0, 0, 0, 250, 1), "<=", 0)
# 4. For Player 2's WBR
add.constraint(lp_player1, c(-400, 0, 0, 0, 0, 400, 1), "<=", 0)
# 5. For Player 2's BRW
add.constraint(lp_player1, c(200, 0, 0, -400, 0, 0, 1), "<=", 0)
add.constraint(lp_player1, c(-100, 400, -400, 0, 0, 0, 1), "<=", 0)
# Probabilities must sum to 1
add.constraint(lp_player1, c(1, 1, 1, 1, 1, 1, 0), "=", 1)
# Set non-negativity constraints for the probabilities
set.bounds(lp_player1, lower = c(0, 0, 0, 0, 0, 0, -Inf), columns = 1:7)
# Solve the LP
solve_status <- solve(lp_player1)
# Check if the solution was found successfully (0 = success)
if (solve_status == 0) {
# Get the value of the game
v_value <- get.objective(lp_player1)
cat("Player 1's expected value (max payoff):", v_value, "\n")
# Get Player 1's optimal strategy (probabilities)
optimal_strategy_player1 <- get.variables(lp_player1)
cat("Player 1's optimal strategy (RWB, RBW, WRB, WBR, BRW, BWR probabilities):", optimal_strategy_player1[1:6], "\n")
} else {
cat("The model could not be solved. Status code:", solve_status, "\n")
}
setwd("/Users/hashaamkhan/Desktop/Deakin/T2/Statistical Data Analysis/Week 9 and 10 Task")
knitr::opts_chunk$set(echo = TRUE)
my_string <- "My name is Hashaam Khan, Unit Name is Statistical Data Analysis and this is Task T 06"
my_string
library(gapminder)
gapminder
library(tidyverse)
afg_data <- gapminder %>% filter(country=="Afghanistan")
gam_afg_default <- gam(lifeExp ~ s(pop), data= afg_data)
library(tidyverse)
library(mgcv)
afg_data <- gapminder %>% filter(country=="Afghanistan")
gam_afg_default <- gam(lifeExp ~ s(pop), data= afg_data)
summary(gam_afg_default)
library(tidyverse)
library(mgcv)
afg_data <- gapminder %>% filter(country=="Afghanistan")
gam_afg_default <- gam(lifeExp ~ s(pop), data= afg_data)
summary(gam_afg_default)
plot(gam_afg_default)
library(tidyverse)
library(mgcv)
afg_data <- gapminder %>% filter(country=="Afghanistan")
gam_afg_default <- gam(lifeExp ~ s(pop), data= afg_data)
summary(gam_afg_default)
plot(gam_afg_default,se=TRUE)
ggplot(afg_data, aes(x = pop, y = lifeExp)) +
geom_point() +
geom_smooth(method = "gam", formula = y ~ s(x), se = TRUE, color = "blue") +
labs(title = "Population vs Life Expectancy in Afghanistan",
x = "Population",
y = "Life Expectancy") +
theme_minimal()
gam_afg_te <- gam(lifeExp ~ te(pop), data= afg_data)
summary(gam_afg_te)
plot(gam_afg_te,se=TRUE)
summary(gam_afg_default)
plot(gam_afg_default,se=TRUE)
```
library(tidyverse)
library(mgcv)
afg_data <- gapminder %>% filter(country=="Afghanistan")
gam_afg_default <- gam(lifeExp ~ s(pop), data= afg_data)
gam_afg_te <- gam(lifeExp ~ te(pop), data= afg_data)
plot(gam_afg_default,se=TRUE)
gam_afg_k <- gam(lifeExp ~ s(pop, k = 15), data = afg_data)
library(tidyverse)
library(mgcv)
afg_data <- gapminder %>% filter(country=="Afghanistan")
gam_afg_default <- gam(lifeExp ~ s(pop), data= afg_data)
gam_afg_te <- gam(lifeExp ~ te(pop), data= afg_data)
plot(gam_afg_default,se=TRUE)
gam_afg_k <- gam(lifeExp ~ s(pop, k = 12), data = afg_data)
# Display summary and compare AIC values
summary(gam_afg_default)
summary(gam_afg_te)
summary(gam_afg_k)
AIC(gam_afg_default, gam_afg_te, gam_afg_k)
library(tidyverse)
library(mgcv)
afg_data <- gapminder %>% filter(country=="Afghanistan")
gam_afg_default <- gam(lifeExp ~ s(pop), data= afg_data)
gam_afg_te <- gam(lifeExp ~ te(pop), data= afg_data)
gam_afg_k <- gam(lifeExp ~ s(pop, k = 12), data = afg_data)
# Display summary and compare AIC values
summary(gam_afg_default)
summary(gam_afg_te)
summary(gam_afg_k)
AIC(gam_afg_default, gam_afg_te, gam_afg_k)
plot(gam_afg_default,se=TRUE)
plot(gam_afg_te,se=TRUE)
plot(gam_afg_k,se=TRUE)
library(tidyverse)
library(mgcv)
afg_data <- gapminder %>% filter(country=="Afghanistan")
gam_afg_default <- gam(lifeExp ~ s(pop), data= afg_data)
gam_afg_te <- gam(lifeExp ~ te(pop), data= afg_data)
gam_afg_k <- gam(lifeExp ~ s(pop, k = 5), data = afg_data)
# Display summary and compare AIC values
summary(gam_afg_default)
summary(gam_afg_te)
summary(gam_afg_k)
AIC(gam_afg_default, gam_afg_te, gam_afg_k)
library(tidyverse)
library(mgcv)
afg_data <- gapminder %>% filter(country=="Afghanistan")
gam_afg_default <- gam(lifeExp ~ s(pop), data= afg_data)
gam_afg_te <- gam(lifeExp ~ te(pop), data= afg_data)
gam_afg_k <- gam(lifeExp ~ s(pop, k = 12), data = afg_data)
# Display summary and compare AIC values
summary(gam_afg_default)
summary(gam_afg_te)
summary(gam_afg_k)
AIC(gam_afg_default, gam_afg_te, gam_afg_k)
library(tidyverse)
library(mgcv)
afg_data <- gapminder %>% filter(country=="Afghanistan")
gam_afg_default <- gam(lifeExp ~ s(pop), data= afg_data)
gam_afg_te <- gam(lifeExp ~ te(pop), data= afg_data)
gam_afg_k <- gam(lifeExp ~ s(pop, k = 2), data = afg_data)
# Display summary and compare AIC values
summary(gam_afg_default)
summary(gam_afg_te)
summary(gam_afg_k)
AIC(gam_afg_default, gam_afg_te, gam_afg_k)
library(tidyverse)
library(mgcv)
afg_data <- gapminder %>% filter(country=="Afghanistan")
gam_afg_default <- gam(lifeExp ~ s(pop), data= afg_data)
gam_afg_te <- gam(lifeExp ~ te(pop), data= afg_data)
gam_afg_k <- gam(lifeExp ~ s(pop, k = 5), data = afg_data)
# Display summary and compare AIC values
summary(gam_afg_default)
summary(gam_afg_te)
summary(gam_afg_k)
AIC(gam_afg_default, gam_afg_te, gam_afg_k)
plot(gam_afg_default,se=TRUE)
plot(gam_afg_te,se=TRUE)
plot(gam_afg_k,se=TRUE)
abalone <- read.table("http://archive.ics.uci.edu/ml/machine-learning-databases/abalone/abalone.data", sep = ",")
names(abalone) <- c("Sex", "Length", "Diameter", "Height", "Whole_weight", "Shucked_weight", "Viscera_weight", "Shell_weight", "Rings")
head(abalone)
abalone <- read.table("http://archive.ics.uci.edu/ml/machine-learning-databases/abalone/abalone.data", sep = ",")
names(abalone) <- c("Sex", "Length", "Diameter", "Height", "Whole_weight", "Shucked_weight", "Viscera_weight", "Shell_weight", "Rings")
abalone
abalone <- read.table("http://archive.ics.uci.edu/ml/machine-learning-databases/abalone/abalone.data", sep = ",")
names(abalone) <- c("Sex", "Length", "Diameter", "Height", "Whole_weight", "Shucked_weight", "Viscera_weight", "Shell_weight", "Rings")
head(abalone)
library(rsample)
set.seed(123)
abalone_cv <- vfold_cv(abalone,v=10)
abalone_cv
library(rsample)
set.seed(123)
abalone_cv <- vfold_cv(abalone,v=10)
abalone_cv
summary(abalone_cv)
library(broom)
library(mgcv)
fit_gam <- function(splt, ...)
gam(..., data = analysis(splt))
predict_gam <- function(splt, mod, ...)
broom::augment(mod, newdata = assessment(splt))
for (i in seq_along(abalone_cv$splits)) {
# Get the current fold (split)
splt <- abalone_cv$splits[[i]]
# Fit the GAM model on the training data
model <- fit_gam(splt, length ~ s(diameter))
# Make predictions on the test data
predictions <- predict_gam(splt, model)
# Store the predictions for this fold
predictions_list[[i]] <- predictions
}
library(broom)
library(mgcv)
fit_gam <- function(splt, ...)
gam(..., data = analysis(splt))
predict_gam <- function(splt, mod, ...)
broom::augment(mod, newdata = assessment(splt))
for (i in seq_along(abalone_cv$splits)) {
# Get the current fold (split)
splt <- abalone_cv$splits[[i]]
# Fit the GAM model on the training data
model <- fit_gam(splt, Length ~ s(Diameter))
# Make predictions on the test data
predictions <- predict_gam(splt, model)
# Store the predictions for this fold
predictions_list[[i]] <- predictions
}
library(broom)
library(mgcv)
fit_gam <- function(splt, ...)
gam(..., data = analysis(splt))
predict_gam <- function(splt, mod, ...)
broom::augment(mod, newdata = assessment(splt))
predictions_list <- list()
for (i in seq_along(abalone_cv$splits)) {
# Get the current fold (split)
splt <- abalone_cv$splits[[i]]
# Fit the GAM model on the training data
model <- fit_gam(splt, Length ~ s(Diameter))
# Make predictions on the test data
predictions <- predict_gam(splt, model)
# Store the predictions for this fold
predictions_list[[i]] <- predictions
}
# Print the first few predictions from the first fold
print(head(predictions_list[[1]]))
library(broom)
library(mgcv)
fit_gam <- function(splt, ...)
gam(..., data = analysis(splt))
predict_gam <- function(splt, mod, ...)
broom::augment(mod, newdata = assessment(splt))
predictions_list <- list()
for (i in seq_along(abalone_cv$splits)) {
# Get the current fold (split)
splt <- abalone_cv$splits[[i]]
# Fit the GAM model on the training data
model <- fit_gam(splt, Length ~ s(Diameter))
# Make predictions on the test data
predictions <- predict_gam(splt, model)
# Store the predictions for this fold
predictions_list[[i]] <- predictions
}
# Print the first few predictions from the first fold
#print(head(predictions_list[[1]]))
predictions_list
# Initialize a vector to store the MSEs for each fold
mse_values <- numeric(length(abalone_cv$splits))
for (i in seq_along(abalone_cv$splits)) {
actual_values <- assessment(abalone_cv$splits[[i]])$length
predicted_values <- predictions_list[[i]]$.fitted
# Calculate the Mean Squared Error (MSE) for this fold
mse_values[i] <- mean((actual_values - predicted_values)^2)
}
# Calculate the mean MSE across all folds
mean_mse <- mean(mse_values)
# Calculate the standard deviation of the MSE across all folds
std_dev_mse <- sd(mse_values)
cat("Mean MSE across all folds:", mean_mse, "\n")
cat("Standard Deviation of MSE across all folds:", std_dev_mse, "\n")
# Initialize a vector to store the MSEs for each fold
mse_values <- numeric(length(abalone_cv$splits))
for (i in seq_along(abalone_cv$splits)) {
actual_values <- assessment(abalone_cv$splits[[i]])$length
predicted_values <- predictions_list[[i]]$.fitted
# Calculate the Mean Squared Error (MSE) for this fold
mse_values[i] <- mean((actual_values - predicted_values)^2)
}
# Calculate the mean MSE across all folds
mean_mse <- mean(mse_values)
# Calculate the standard deviation of the MSE across all folds
std_dev_mse <- sd(mse_values)
mse_values
cat("Mean MSE across all folds:", mean_mse, "\n")
cat("Standard Deviation of MSE across all folds:", std_dev_mse, "\n")
# Initialize a vector to store the MSEs for each fold
mse_values <- numeric(length(abalone_cv$splits))
for (i in seq_along(abalone_cv$splits)) {
actual_values <- assessment(abalone_cv$splits[[i]])$length
predicted_values <- predictions_list[[i]]$.fitted
actual_values
# Calculate the Mean Squared Error (MSE) for this fold
mse_values[i] <- mean((actual_values - predicted_values)^2)
}
# Calculate the mean MSE across all folds
mean_mse <- mean(mse_values)
# Calculate the standard deviation of the MSE across all folds
std_dev_mse <- sd(mse_values)
cat("Mean MSE across all folds:", mean_mse, "\n")
cat("Standard Deviation of MSE across all folds:", std_dev_mse, "\n")
actual_values
# Initialize a vector to store the MSEs for each fold
mse_values <- numeric(length(abalone_cv$splits))
for (i in seq_along(abalone_cv$splits)) {
actual_values <- assessment(abalone_cv$splits[[i]])$Length
predicted_values <- predictions_list[[i]]$.fitted
# Calculate the Mean Squared Error (MSE) for this fold
mse_values[i] <- mean((actual_values - predicted_values)^2)
}
# Calculate the mean MSE across all folds
mean_mse <- mean(mse_values)
# Calculate the standard deviation of the MSE across all folds
std_dev_mse <- sd(mse_values)
cat("Mean MSE across all folds:", mean_mse, "\n")
cat("Standard Deviation of MSE across all folds:", std_dev_mse, "\n")
setwd("~/Desktop/Deakin/T2/Statistical Data Analysis/Week 9 and 10 Task")
setwd("/Users/hashaamkhan/Desktop/Deakin/T2/Statistical Data Analysis/Code")
knitr::opts_chunk$set(echo = TRUE)
car_accidents <- read.csv("car_accidents_victoria.csv")
dim(car_accidents)
structure(car_accidents)
structure(car_accidents)
library(tidyverse)
car_accidents2 <- read_csv("car_accidents_victoria.csv", skip = 1)
# Create a new data frame that combines all region columns into a 'Region' column
car_accidents_tidy <- car_accidents2 %>%
pivot_longer(cols = c("EASTERN REGION", "METROPOLITAN NORTH WEST REGION",
"METROPOLITAN SOUTH EAST REGION",
"NORTH EASTERN REGION", "NORTHERN REGION",
"SOUTH WESTERN REGION", "WESTERN REGION"),
names_to = "Region",
values_to = "Accident_Count") %>%
filter(!is.na(Accident_Count)) # Filter out rows with missing accident data
library(tidyverse)
car_accidents2 <- read_csv("car_accidents_victoria.csv")
# Create a new data frame that combines all region columns into a 'Region' column
car_accidents_tidy <- car_accidents2 %>%
pivot_longer(cols = c("EASTERN REGION", "METROPOLITAN NORTH WEST REGION",
"METROPOLITAN SOUTH EAST REGION",
"NORTH EASTERN REGION", "NORTHERN REGION",
"SOUTH WESTERN REGION", "WESTERN REGION"),
names_to = "Region",
values_to = "Accident_Count") %>%
filter(!is.na(Accident_Count)) # Filter out rows with missing accident data
# View the first few rows of the new dataset
head(car_accidents_tidy)
library(tidyverse)
car_accidents2 <- read_csv("car_accidents_victoria.csv")
# Create a new data frame that combines all region columns into a 'Region' column
car_accidents_tidy <- car_accidents2 %>%
pivot_longer(cols = c("EASTERN REGION", "METROPOLITAN NORTH WEST REGION",
"METROPOLITAN SOUTH EAST REGION",
"NORTH EASTERN REGION", "NORTHERN REGION",
"SOUTH WESTERN REGION", "WESTERN REGION"),
names_to = "Region",
values_to = "Accident_Count") %>%
filter(!is.na(Accident_Count)) # Filter out rows with missing accident data
# View the first few rows of the new dataset
car_accidents_tidy
View(car_accidents_tidy)
View(car_accidents_tidy)
car_accidents
column_names <- c("DATE", "Region_Fatal", "Region_Serious", "Region_NoInjury", "Region_Other",
"MetroNW_Fatal", "MetroNW_Serious", "MetroNW_NoInjury", "MetroNW_Other",
"MetroSE_Fatal", "MetroSE_Serious", "MetroSE_NoInjury", "MetroSE_Other",
"NorthEast_Fatal", "NorthEast_Serious", "NorthEast_NoInjury", "NorthEast_Other",
"Northern_Fatal", "Northern_Serious", "Northern_NoInjury", "Northern_Other",
"SouthWest_Fatal", "SouthWest_Serious", "SouthWest_NoInjury", "SouthWest_Other",
"Western_Fatal", "Western_Serious", "Western_NoInjury", "Western_Other")
# Reassign the first row as column names
colnames(car_accidents) <- column_names
# Remove the first row which is now used as column names
car_accidents <- car_accidents[-1,]
# Reshape the data to create a Region column and corresponding accident counts
car_accidents_tidy <- car_accidents %>%
pivot_longer(cols = starts_with("Region"),
names_to = "Region_AccidentType",
values_to = "Accident_Count") %>%
mutate(Region = case_when(
str_detect(Region_Type, "Region") ~ "Eastern",
str_detect(Region_Type, "MetroNW") ~ "Metropolitan North West",
str_detect(Region_Type, "MetroSE") ~ "Metropolitan South East",
str_detect(Region_Type, "NorthEast") ~ "North Eastern",
str_detect(Region_Type, "Northern") ~ "Northern",
str_detect(Region_Type, "SouthWest") ~ "South Western",
str_detect(Region_Type, "Western") ~ "Western"
))
column_names <- c("DATE", "Region_Fatal", "Region_Serious", "Region_NoInjury", "Region_Other",
"MetroNW_Fatal", "MetroNW_Serious", "MetroNW_NoInjury", "MetroNW_Other",
"MetroSE_Fatal", "MetroSE_Serious", "MetroSE_NoInjury", "MetroSE_Other",
"NorthEast_Fatal", "NorthEast_Serious", "NorthEast_NoInjury", "NorthEast_Other",
"Northern_Fatal", "Northern_Serious", "Northern_NoInjury", "Northern_Other",
"SouthWest_Fatal", "SouthWest_Serious", "SouthWest_NoInjury", "SouthWest_Other",
"Western_Fatal", "Western_Serious", "Western_NoInjury", "Western_Other")
# Reassign the first row as column names
colnames(car_accidents) <- column_names
# Remove the first row which is now used as column names
car_accidents <- car_accidents[-1,]
# Reshape the data to create a Region column and corresponding accident counts
car_accidents_tidy <- car_accidents %>%
pivot_longer(cols = starts_with("Region"),
names_to = "Region_AccidentType",
values_to = "Accident_Count") %>%
mutate(Region = case_when(
str_detect(Region_AccidentType, "Region") ~ "Eastern",
str_detect(Region_AccidentTypee, "MetroNW") ~ "Metropolitan North West",
str_detect(Region_AccidentType, "MetroSE") ~ "Metropolitan South East",
str_detect(Region_AccidentType, "NorthEast") ~ "North Eastern",
str_detect(Region_AccidentType, "Northern") ~ "Northern",
str_detect(Region_AccidentType, "SouthWest") ~ "South Western",
str_detect(Region_AccidentType, "Western") ~ "Western"
))
# Load necessary libraries
library(tidyverse)
# Load the dataset without skipping the first row
car_accidents <- read_csv("path_to_your_file/car_accidents_victoria.csv")
# Load necessary libraries
library(tidyverse)
# Extract the column names from the first row and assign them to a new vector
column_names <- c("DATE", "Region_Fatal", "Region_Serious", "Region_NoInjury", "Region_Other",
"MetroNW_Fatal", "MetroNW_Serious", "MetroNW_NoInjury", "MetroNW_Other",
"MetroSE_Fatal", "MetroSE_Serious", "MetroSE_NoInjury", "MetroSE_Other",
"NorthEast_Fatal", "NorthEast_Serious", "NorthEast_NoInjury", "NorthEast_Other",
"Northern_Fatal", "Northern_Serious", "Northern_NoInjury", "Northern_Other",
"SouthWest_Fatal", "SouthWest_Serious", "SouthWest_NoInjury", "SouthWest_Other",
"Western_Fatal", "Western_Serious", "Western_NoInjury", "Western_Other")
# Reassign the first row as column names
colnames(car_accidents) <- column_names
# Remove the first row which is now used as column names
car_accidents <- car_accidents[-1,]
# Reshape the data to create a Region column and corresponding accident counts
car_accidents_tidy <- car_accidents %>%
pivot_longer(cols = starts_with("Region"),
names_to = "Region_Type",
values_to = "Accident_Count") %>%
mutate(Region = case_when(
str_detect(Region_Type, "Region") ~ "Eastern",
str_detect(Region_Type, "MetroNW") ~ "Metropolitan North West",
str_detect(Region_Type, "MetroSE") ~ "Metropolitan South East",
str_detect(Region_Type, "NorthEast") ~ "North Eastern",
str_detect(Region_Type, "Northern") ~ "Northern",
str_detect(Region_Type, "SouthWest") ~ "South Western",
str_detect(Region_Type, "Western") ~ "Western"
))
# View the tidied dataset
head(car_accidents_tidy)
View(car_accidents_tidy)
View(car_accidents)
